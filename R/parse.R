#' From html to dataframe with text
#'
#' @description
#' turns the pure html text of the tacquigraphic notes, into
#' an structured tibble/ data.frame with two columns: Title and text. The results
#' from this function is send further to the parser function
#'
#' @param html_page the pure html text of the tacquigraphic notes. It can be the
#' html text as well as the "xml_document". It does not accept the URL as input
#'
#' file_html <- list.files("inst/extdata/", full.names = TRUE)
#' NT_html <- xml2::read_html(file_html,encoding = "utf8")
#' from_html_2_df(NT_html)
from_html_2_df <- function(html_page) {
  # html_page = NT_html
  # html_page <- page

  # NT_html |>
  text <- html_page |>
    as.character() |>
    gsub(x = _, "(<b>)", "<break_line>\\1") |>
    paste(collapse = " ") |>
    xml2::read_html(encoding = "utf8") |>
    rvest::html_elements("break_line") |>
    rvest::html_text()

  # transform data type of input
  if (typeof(html_page) == "character") {
    html_page <- xml2::read_html(
      paste(html_page, collapse = " "),
      encoding = "utf8"
    )
  }

  # NT_html |>
  Title <- html_page |>
    rvest::html_elements("h1") |>
    rvest::html_text() |>
    grep("\\d+/\\d+", x = _, value = TRUE)

  if (length(Title) == 0) {
    Title <- html_page |>
      rvest::html_elements("strong") |>
      rvest::html_text() |>
      paste(collapse = " ") |>
      gsub("\\s+", " ", x = _)
  }

  tibble::tibble(Title, text)
}


#' Extract metadata from text column from dataframe
#'
#' input is DF generated by from_html_2_df(), export a DF with more columns
#'
#' @param DF the dataframe generated by from_html_2_df
#'
#' @export
#'
#' @examples
#' file_html <- list.files("inst/extdata/", full.names = TRUE, pattern = "NT_")
#' NT_html <- xml2::read_html(file_html, encoding = "utf8")
#' extract_metadata(NT_html)
extract_metadata <- function(DF) {
  # TODO add parameter = normalize_president. To change columns
  # DF <- from_html_2_df(NT_html)
  # DF <-  test_files_list[[1]] |> extract_metadata()
  # DF <- NT_html
  # rgx_metaData <- "^.*)"

  rgx_date <- "\\d+/\\d+/\\d+"

  DF <- from_html_2_df(DF)

  DF2 <- DF |> # dplyr::select(text) |>
    dplyr::mutate(
      Date = stringr::str_extract(Title, rgx_date) |> as.Date("%d/%m/%Y"),
      Title = stringr::str_remove(Title, rgx_date),
      # reunion_n = stringr::str_replace(Titre, ".* - (\\d+) - .*", "\\1"),
      reunion_n = Title |>
        strsplit("-") |> unlist() |>
        grep("\\d+", x = _, value = TRUE) |>
        stringr::str_trim(),
      # stringr::str_replace(, ".* - (\\d+) - .*", "\\1"),
      Title = Title |>
        strsplit("-") |>
        unlist() |>
        dplyr::nth(3) |>
        stringr::str_trim(),
      metadata = text |>
        substring(1, 300) |>
        stringr::str_extract_all(".*\\)", simplify = TRUE) |>
        as.vector(),
      # if metadata is empty, because there is no info (spaker) until parenthesis
      metadata = ifelse(metadata == "",
        text |>
          substring(1, 300) |>
          stringr::str_extract_all(".* \\W ", simplify = TRUE),
        metadata
      ),
      gentilic = metadata |>
        substring(1, 10) |>
        # stringr::str_extract_all("(\\b[sSdD][Rr][aA]?\\b)", simplify = TRUE), # |> # unlist(use.names = FALSE)
        # stringr::str_extract_all("((?i)[sd][r][a\\. ]{0,3})*", simplify = TRUE) |> # unlist(use.names = FALSE)
        stringr::str_extract_all("\\b((?i)[SD][R][A\\. ]{0,3}\\b)+", simplify = TRUE) |> # unlist(use.names = FALSE)
        # gsub(x = _, "^.*([SD][R][a\\. ]{0,3})*(.*)", "\\1", ignore.case = TRUE) |>
        trimws() |> as.vector(),
      # paste(collapse = " "), #|> as.vector(),
      speaker = metadata |>
        gsub(x = _, "^[OAoa] [SsRr]{2}[aA]?[\\. ]+", "") |> # erase "O SR" at the beginning
        gsub(x = _, " \\W $", "") |> # erase " - " at the end
        gsub(x = _, " +\\(.*", "") |>
        trimws(),
      metadata2 = metadata |> # metadata inside parenthesis, e.g,: "("Dr. Hiran. Bloco Parlamentar Aliança/PP - RR)"
        stringr::str_extract_all("\\(.*\\)", simplify = TRUE) |>
        # stringr::str_remove_all( "\\\\(")
        # gsub(x=_, r"([\(\)])", ""),
        stringr::str_remove_all("\\(|\\)"),
      party_UF = metadata2 |>
        stringr::str_extract_all("\\W\\w+ \\W [A-Z]{2}", simplify = TRUE) |>
        stringr::str_remove_all("\\/"),
      party = party_UF |>
        gsub(x = _, "(\\w*)[\\W -]+.*[A-Z]{2}", "\\1"),
      state = party_UF |>
        gsub(x = _, "(\\w*)[\\W -]+.*([A-Z]{2})", "\\2"),
      # complement = TODO
      block = metadata2 |>
        # gsub(x=_, "^([A-Za-z ]+)[\\/\\-].*", "\\1")
        gsub(x = _, "^(.*)\\/.*", "\\1")
    ) |>
    dplyr::mutate(text = stringr::str_remove_all(text, "^.*\\) - ")) |>
    dplyr::select(-party_UF, -metadata2) |>
    # reordering the columns
    dplyr::select(
      Title, Date, reunion_n, speaker, gentilic, party, state, block,
      metadata, text
    )

  # when speaker is president, change columns
  DF2 |> # dplyr::pull(block)
    dplyr::mutate(
      is_chef = grepl("PRESIDENT", x = speaker),
      role = ifelse(is_chef, speaker, ""),
      speaker = ifelse(is_chef,
        {
          gsub(x = block, "(.*) Bloco.*", "\\1")
        },
        speaker
      ),
      block = gsub(x = block, "(.*)((Bloco|BLOCO).*)", "\\2")
    ) |> dplyr::select(-is_chef)
}




#' Save structured data from extract_metadata
#'
#' input is DF generated by from_html_2_df(), export a DF with more columns
#'
#' @param DF the dataframe generated by extract_metadata
#' @param save_as = "rds" (default). To save the files in .rds and .csv.
#'
save_csv_rds <- function(NTDB, save_as = NULL) {
  nomearq <-
    paste0(
      "NT_", DF[linha, ]$reuniao_dia, "-",
      DF[linha, ]$Depoente.tema
    ) |>
    gsub("ª|,", "", x = _) |>
    gsub(" - ", "-", x = _) |>
    gsub(" ", "_", x = _)

  if (save_as == "both") {
    dir.create(paste0(getwd(), "/", cod, "/rds"), recursive = T, showWarnings = FALSE)
    dir.create(paste0(getwd(), "/", cod, "/csv"), recursive = T, showWarnings = FALSE)

    write.csv(NTDB, paste0(cod, "/csv/", nomearq, ".csv"))
    save_asRDS(NTDB, paste0(cod, "/rds/", nomearq, ".Rds"))
  } else if (save_as == "rds") {
    dir.create(paste0(getwd(), "/", cod, "/rds"), recursive = T, showWarnings = FALSE)
    save_asRDS(NTDB, paste0(cod, "/rds/", nomearq, ".Rds"))
  } else if (save_as == "csv") {
    dir.create(paste0(getwd(), "/", cod, "/csv"), recursive = T, showWarnings = FALSE)
    write.csv(NTDB, paste0(cod, "/csv/", nomearq, ".csv"))
  } else {
    stop("invalid option", save_as)
  }
}


#' Parse the tacquigraphic notes text
#'
#' Turns the pure .html text of the tacquigraphic notes, into an structured
#' tibble/ data.frame.
#'
#' @param html_page the dataframe generated with meetings()
#' @param save_as To save the files in .rds and .csv. If empty, the files
#' will not be saved.
#'
#' @export
#'
#' @examples
#' # parse_TN("https://www25.senado.leg.br/web/atividade/notas-taquigraficas/-/notas/r/13611")
#' file_html <- list.files("inst/extdata/", full.names = TRUE)
#' TN_html <- xml2::read_html(file_html, encoding = "utf8")
#' parse_TN(TN_html)
parse_TN <- function(html_page, save_as) {
  if (any(class(html_page) %in% "xml_document")) {
    DF <- extract_metadata(html_page)
  } else {
    DF <- html_page |>
      rvest::read_html(encoding = "utf8") |>
      extract_metadata()
  }
  # save_as
  if (exists("save_as")) {
    DF
  } else {
    save_csv_rds(DF, save_as)
  }

  return(DF)
}
