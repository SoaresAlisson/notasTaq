
#' From html to dataframe with text
#'
#' @description
#' turns the pure html text of the tacquigraphic notes, into
#' an structured tibble/ data.frame with two columns: title and text. The results
#' from this function is send further to the parser function
#'
#' @param html_page the pure html text of the tacquigraphic notes. It can be the
#' html text as well as the "xml_document". It does not accept the URL as input
#' 
#' file_html <- list.files("inst/extdata/", full.names = TRUE)
#' NT_html <- xml2::read_html(file_html,encoding = "utf8")
#' from_html_2_df(NT_html)
from_html_2_df <- function(html_page) {
# html_page = NT_html 

  # NT_html |> 
  text <- html_page |> 
    as.character() |>
    gsub(x=_, "(<b>)", "<break_line>\\1") |>
    paste(collapse = " ") |>
    xml2::read_html(encoding = "utf8") |>
    rvest::html_elements("break_line") |>
    rvest::html_text()

  # transform data type of input
  if (typeof(html_page) == "character") {
    html_page <- xml2::read_html(
      paste(html_page, collapse = " "), 
      encoding = "utf8")
  }

  # NT_html |> 
  title <- html_page |> 
      rvest::html_elements("h1") |> 
      rvest::html_text() |> 
      grep("\\d+/\\d+", x=_, value = TRUE)

  tibble::tibble(title, text) 
}


#' Extract metadata from text column from dataframe
#'
#' input is DF generated by from_html_2_df(), export a DF with more columns
#'
#' @param DF the dataframe generated by from_html_2_df
#' 
#' @export
#'
#' @examples
#' file_html <- list.files("inst/extdata/", full.names=TRUE)
#' NT_html <- xml2::read_html(file_html,encoding = "utf8")
#' extract_metadata(NT_html)
extract_metadata <- function(DF) {
  # TODO add parameter = normalize_president. To change columns
  # DF <- from_html_2_df(NT_html)
  # DF <-  test_files_list[[1]] |> extract_metadata()
  # rgx_metaData <- "^.*)"

  DF <- from_html_2_df(DF)
  
  DF2 <- DF |> # dplyr::select(text) |> 
    dplyr::mutate(
      metadata = text |> 
        substring(1,300) |> 
        # stringr::str_extract_all( rgx_metaData, simplify = TRUE) |>
        stringr::str_extract_all( ".*\\)", simplify = TRUE),
      gentilic = metadata |>
        substring(1,10) |> 
        stringr::str_extract_all( "([sSdD][Rr][aA]?)", simplify = TRUE),
      speaker = metadata |>
        gsub(x=_,"^[OAoa] [SsRr]{2}[aA]?[\\. ]+","") |> # erase "O SR" at the beginning
        gsub(x=_, " +\\(.*", ""),
      metadata2 = metadata |> # metadata inside parenthesis, e.g,: "("Dr. Hiran. Bloco Parlamentar Aliança/PP - RR)"
        stringr::str_extract_all("\\(.*\\)", simplify = TRUE) |>
         # stringr::str_remove_all( "\\\\(")
        gsub(x=_, r"([\(\)])", ""),
      party_UF = metadata2 |>
        stringr::str_extract_all("\\W\\w+ \\W [A-Z]{2}", simplify = TRUE) |> 
        gsub(x=_,"\\/", ""),
      party = party_UF |> 
        gsub(x=_, "(\\w*)[\\W -]+.*[A-Z]{2}", "\\1" ),
      state =  party_UF |> 
        gsub(x=_, "(\\w*)[\\W -]+.*([A-Z]{2})", "\\2"),
      # complement = TODO 
      block = metadata2 |> 
        # gsub(x=_, "^([A-Za-z ]+)[\\/\\-].*", "\\1")
        gsub(x=_, "^(.*)\\/.*", "\\1")
  ) |> 
    dplyr::select(-party_UF, -metadata2)  |> 
    # reordering the columns
    dplyr::select(title, speaker, gentilic, party, state, block, 
      metadata, text)

  # when speaker is president, change columns
  DF2 |> # dplyr::pull(block)
    dplyr::mutate(
      is_chef = grepl("PRESIDENT", x = speaker),
      role = ifelse(is_chef, speaker, "" ),
      speaker = ifelse(is_chef, 
        {gsub(x=block, "(.*) Bloco.*", "\\1")} ,
        speaker),
      block = gsub(x=block,"(.*)((Bloco|BLOCO).*)", "\\2")
    ) |> dplyr::select(-is_chef)
  
}

#' Save structured data from extract_metadata
#'
#' input is DF generated by from_html_2_df(), export a DF with more columns
#'
#' @param save_as = "rds" (default). To save the files in .rds and .csv.
#' 
save_csv_rds <- function(NTDB, save_as = NULL) {

  nomearq <- 
    paste0("NT_",DF[linha,]$reuniao_dia, "-", 
      DF[linha,]$Depoente.tema) |>
      gsub("ª|,", "", x=_) |> 
      gsub(" - ", "-", x=_) |> 
      gsub(" ", "_", x=_)
    
  if (save_as == "both") {  
      dir.create(paste0(getwd(),"/", cod, "/rds"), recursive = T, showWarnings = FALSE)
      dir.create(paste0(getwd(), "/", cod, "/csv"),  recursive = T, showWarnings = FALSE)

      write.csv(NTDB, paste0( cod, "/csv/", nomearq, ".csv"))
      save_asRDS(NTDB, paste0(cod, "/rds/", nomearq, ".Rds"))
  } else if (save_as == "rds"){ 
      dir.create(paste0(getwd(),"/", cod, "/rds"), recursive = T, showWarnings = FALSE)
      save_asRDS(NTDB, paste0(cod, "/rds/", nomearq, ".Rds"))
  } else if (save_as == "csv"){
      dir.create(paste0(getwd(), "/", cod, "/csv"),  recursive = T, showWarnings = FALSE)
      write.csv(NTDB, paste0( cod, "/csv/", nomearq, ".csv"))
  } else {
      stop("invalid option", save_as)
  }

}


#' Parse the tacquigraphic notes text
#'
#' turns the pure .html text of the tacquigraphic notes, into an structured 
#' tibble/ data.frame.
#'
#' @param html_page the dataframe generated with meetings()
#'
#' @examples
#' df <- meetings(cod = "2606", start = "2023-05-25")
#' parser( df, 1 )
#'
#' @export
#'
#' parse("https://www25.senado.leg.br/web/atividade/notas-taquigraficas/-/notas/r/13611")
#' file_html <- list.files("inst/extdata/", full.names=TRUE)
#' NT_html <- xml2::read_html(file_html,encoding = "utf8")
#' parse(NT_html)
parse <- function(html_page, save_as) {

  if (any(class(html_page) %in% "xml_document" )){
      DF <- extract_metadata(html_page)
  } else{ 
      DF <- html_page |> 
        rvest::read_html() |>
        extract_metadata()
  }
  # save_as
  if ( exists("save_as") ){
      DF
  } else {
      save_csv_rds(DF, save_as)
  }

  return(DF)
}

